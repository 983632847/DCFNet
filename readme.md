# DeepKCF

首先，KCF+HOG特征取得了非常好的速度与精度的平衡，在此基础上发展了CF2,DeepSRDCF等CNN特征加上KCF的方法，但是他们都是直接采用vgg在imagenet库上训练好的模型，这些模型并不一定适应于跟踪问题。

那么我们仔细分析，如果只是考虑一种编码问题，或者特征空间的投影，hog实际上是对每个cell进行了一个编码。对于KCF来说是一个4*4的cell，产生了31维的的编码，在这个编码的基础上进行了DCF运算。（不考虑kernel trick）。

那么CF2使用了cf2的多层特征进行融合。

```
indLayers = [37, 28, 19];   % The CNN layers Conv5-4, Conv4-4, and Conv3-4 in VGG Net

nweights  = [1, 0.5, 0.02]; % Weights for combining correlation filter responses
```
对应的感受野分别是[];
其最终的结果为0.891 0.605
相对于KCF的提升还是很显著的。但是问题是，这样的特征是实验出来的，跑了很多参数自然不必说，那么最好的方法当时是对应KCF的end-to-end的训练，同时，注意到，Siamese-fc其实就是一个end-to-end的很好的事例，但是缺陷是最好一级的ncc。本身cnn就是位置无关的，ncc对每个位置也是均衡加权，所以不是很好，所以作者用一个高斯窗口进行加权，但还是没有kcf这样的优化解（回归问题）好。所以我认为cnn+kcf的end-to-end训练是最好的一种解。
另外，KCF框架也可以作为网络的一个重要部件，因为他不仅在最后一段产生了在线学习（注意是超快速的在线学习，学习效果并不比svm弱），另外一个重要的原因是，KCF能带来时序信息，并且不增加额外的计算，想象一下，LSTM可以做最后一集合（ROLO），但是随着step的增加，速度必然下降。虽然效果好，那你还是一个短时的滑窗。并且ROLO的很要命的弱点是，他是针对人，或者训练好的物体，这不符合常规的单目标的假定。原因就是，要想搞定通用物体的LSTM，你需要无比巨大的数据，我在训练GOTURN的时候，就直接对这种回归的方法产生了一定的抵触。


下面进入我的实验思考环节。第一步，如何在KCF的基础上改进呢。Martin Danelljan已经把理论部分做的没太多可做了，大家也灌水不少，那还是从特征出发吧，毕竟我这个工作想的是end-to-end kcf。那么一上来要直接重写个kcf层么，先别这么宏远，我们先来**学习hog**。

这非常的重要，我想明白直接cnn的特征不work，或者还有最优，到底什么样的才是最优。既然开山鼻祖给我们留下了hog，只有[4*4]的感受野，31个feature map。可以产生这么好的性能，我觉得首先肯定值得学习hog特征。鉴于在归一化的时候还是用了临近的一个cell，所以，最多的感受野也就是8，那么我么就直接上[3*3]的小卷积核，[3-3-31],这样最简单粗暴，但是显然是不对的，非线性跑哪里去了。那就按照vgg的框架来吧。下面是实验具体细节。

## Train

### Experiment1 （hog）





